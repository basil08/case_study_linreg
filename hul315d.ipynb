{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: \n",
    "# Do analysis for 2008 data\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.graph_objects as go\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gini = pd.read_csv('./data/gini.csv')\n",
    "\n",
    "print(gini.shape)\n",
    "\n",
    "gini18 = gini[[\"Country Name\", \"Country Code\", \"2017\", \"2018\", \"2019\"]]\n",
    "print(gini18.shape)\n",
    "\n",
    "# filter out rows with missing all 2017, 2018 and 2019 values\n",
    "gini18 = gini18.dropna(subset=[\"2017\", \"2018\", \"2019\"], how='all')\n",
    "print(gini18.shape)\n",
    "\n",
    "# if 2018 is missing, use 2017 and 2019 to fill it\n",
    "# gini18[\"2018\"] = gini18[\"2018\"].fillna((gini18[\"2017\"] + gini18[\"2019\"]) / 2)\n",
    "# if gini18[\"2018\"].isna():\n",
    "#     gini18[\"2018\"] = gini18[\"2017\"] if gini18[\"2018\"].isna() else gini18[\"2018\"]\n",
    "    \n",
    "# if 2018 is missing, use 2017 value to fill it, if 2017 is also missing, use 2019 value\n",
    "gini18[\"2018\"] = gini18[\"2018\"].fillna(gini18[\"2017\"])\n",
    "gini18[\"2018\"] = gini18[\"2018\"].fillna(gini18[\"2019\"])\n",
    "\n",
    "\n",
    "print(gini18.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "incomet = pd.read_csv('./data/income_top_10.csv')\n",
    "incomet = incomet[[\"Country Name\", \"Country Code\", \"2017\", \"2018\", \"2019\"]]\n",
    "\n",
    "print(incomet.shape)\n",
    "incomet = incomet.dropna(subset=[\"2017\", \"2018\", \"2019\"], how='all')\n",
    "\n",
    "# incomet[\"2018\"] = incomet[\"2018\"].fillna((incomet[\"2017\"] + incomet[\"2019\"]) / 2)\n",
    "incomet[\"2018\"] = incomet[\"2018\"].fillna(incomet[\"2017\"])\n",
    "incomet[\"2018\"] = incomet[\"2018\"].fillna(incomet[\"2019\"])\n",
    "\n",
    "print(incomet.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "incomeb = pd.read_csv('./data/income_bot_10.csv')\n",
    "incomeb = incomeb[[\"Country Name\", \"Country Code\", \"2017\", \"2018\", \"2019\"]]\n",
    "print(incomeb.shape)\n",
    "incomeb = incomeb.dropna(subset=[\"2017\", \"2018\", \"2019\"], how='all')\n",
    "incomeb[\"2018\"] = incomeb[\"2018\"].fillna(incomeb[\"2017\"])\n",
    "incomeb[\"2018\"] = incomeb[\"2018\"].fillna(incomeb[\"2019\"])\n",
    "print(incomeb.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading the regressor dataframes\n",
    "gdp = pd.read_csv('./data/gdp_per_capita.csv')\n",
    "lit = pd.read_csv('./data/literacy_rate.csv')\n",
    "lif = pd.read_csv('./data/life_expectancy.csv')\n",
    "urb = pd.read_csv('./data/urban_population_percentage.csv')\n",
    "pop = pd.read_csv('./data/population_density.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_up(target, frames):\n",
    "    \"\"\"\n",
    "    target: the dataframe to be used for cleaning\n",
    "    frames: the list of dataframes to be cleaned\n",
    "    \n",
    "    Returns X, y where X is the feature matrix combining all the dataframes in frames and y is the target dataframe\n",
    "    \"\"\"\n",
    "    countries = target[\"Country Code\"]\n",
    "    print(countries.shape)\n",
    "    X = pd.DataFrame()\n",
    "    for name, frame in frames.items():\n",
    "        # for each frame, filter out the rows that are not in the countries list\n",
    "        # print(frame.columns)\n",
    "        frame = frame[[\"Country Code\", \"2017\", \"2018\", \"2019\"]]\n",
    "        frame = frame[frame[\"Country Code\"].isin(countries)]\n",
    "        # now, check if atleast one of 2017, 2018, 2019 is missing\n",
    "        frame = frame.dropna(subset=[\"2017\", \"2018\", \"2019\"], how='all')\n",
    "        # if 2018 is missing, use 2017 and 2019 to fill it\n",
    "        frame[name] = frame[\"2018\"].fillna((frame[\"2017\"] + frame[\"2019\"]) / 2)\n",
    "        \n",
    "        # drop 2018, 2019, 2017 columns from frame\n",
    "        frame = frame.drop(columns=[\"2017\", \"2018\", \"2019\"])\n",
    "        # print(frame.shape)\n",
    "        # concat the frame with X\n",
    "        # if len(X) == 0:\n",
    "        #     X = frame\n",
    "        # else:\n",
    "        #     X = pd.merge(X, frame, on=\"Country Code\", how=\"outer\")\n",
    "        X = pd.concat([X, frame], axis=1)\n",
    "    \n",
    "    # filter out all rows from X that has any missing value\n",
    "    \n",
    "    X = pd.concat([X, target[\"2018\"]], axis=1)\n",
    "    \n",
    "    X = X.dropna()\n",
    "    # only keep one Country Code col and drop the other two in X\n",
    "    X = X.drop(columns=[\"Country Code\"])\n",
    "    \n",
    "    \n",
    "    # extract last column from X and drop that col from X as well\n",
    "    y = X[\"2018\"]\n",
    "    X = X.drop(columns=[\"2018\"])\n",
    "    # y = target[\"2018\"]\n",
    "    return X, y\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gini index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frames = {\n",
    "    \"gdp\": gdp,\n",
    "    # \"lit\": lit,\n",
    "    \"lif\": lif,\n",
    "    \"urb\": urb,\n",
    "    \"pop\": pop\n",
    "}\n",
    "X, y = clean_up(gini18, frames)\n",
    "print(X.shape, y.shape)\n",
    "\n",
    "est2 = sm.add_constant(X)\n",
    "est = sm.OLS(y, est2).fit()\n",
    "print(est.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform gdp to log gdp\n",
    "# X[\"gdp\"] = np.log(X[\"gdp\"]) \n",
    "\n",
    "X[\"log_gdp\"] = np.log(X[\"gdp\"])\n",
    "X[\"gdp_2\"] = X[\"gdp\"] ** 2\n",
    "\n",
    "# gdp + gdp_2 = 0.218\n",
    "# gdp = 0.18\n",
    "# gdp + log gdp = 0.195\n",
    "# gdp + log gdp + gdp_2 = 0.219\n",
    "# gdp + gdp_2 + gdp_3 = 0.071\n",
    "\n",
    "print(X.columns)\n",
    "est2 = sm.add_constant(X)\n",
    "est = sm.OLS(y, est2).fit()\n",
    "print(est.summary())\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Heteroskedasticity test\n",
    "\n",
    "# Plot the residual error terms against the y_pred\n",
    "y_pred = est.predict(est2)\n",
    "\n",
    "residuals = y - y_pred\n",
    "plt.scatter(y_pred, residuals)\n",
    "plt.xlabel(\"Predicted values\")\n",
    "plt.ylabel(\"Residuals\")\n",
    "plt.title(\"Residuals vs Fitted\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variance Inflation Factor\n",
    "\n",
    "# Calculate the VIF for each estimated coefficient using statsmodels package\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "\n",
    "vif = pd.DataFrame()\n",
    "vif[\"VIF Factor\"] = [variance_inflation_factor(X.values, i) for i in range(X.shape[1])]\n",
    "vif"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frames = {\n",
    "    \"gdp\": gdp,\n",
    "    # \"lit\": lit,\n",
    "    \"lif\": lif,\n",
    "    # \"urb\": urb,\n",
    "    \"pop\": pop\n",
    "}\n",
    "X, y = clean_up(gini18, frames)\n",
    "print(X.shape, y.shape)\n",
    "\n",
    "est2 = sm.add_constant(X)\n",
    "est = sm.OLS(y, est2).fit()\n",
    "print(est.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Addition of new variables makes the model explain better (increments of R2 consistent with increase in number of variables)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Income top 10% "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frames = {\n",
    "    \"gdp\": gdp,\n",
    "    # \"lit\": lit,\n",
    "    \"lif\": lif,\n",
    "    \"urb\": urb, \n",
    "    \"pop\": pop\n",
    "}\n",
    "X, y = clean_up(incomet, frames)\n",
    "print(X.shape, y.shape)\n",
    "\n",
    "est2 = sm.add_constant(X)\n",
    "est = sm.OLS(y, est2).fit()\n",
    "print(est.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform gdp to log gdp\n",
    "# X[\"gdp\"] = np.log(X[\"gdp\"]) \n",
    "\n",
    "X[\"log_gdp\"] = np.log(X[\"gdp\"])\n",
    "X[\"gdp_2\"] = X[\"gdp\"] ** 2\n",
    "\n",
    "# gdp = 0.19\n",
    "# gdp + log_gdp = 0.226\n",
    "# gdp + gdp_2 = 0.230\n",
    "# gdp + log_gdp + gdp_2 = 0.241\n",
    "\n",
    "print(X.columns)\n",
    "est2 = sm.add_constant(X)\n",
    "est = sm.OLS(y, est2).fit()\n",
    "print(est.summary())\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Heteroskedasticity test\n",
    "\n",
    "# Plot the residual error terms against the y_pred\n",
    "y_pred = est.predict(est2)\n",
    "\n",
    "residuals = y - y_pred\n",
    "plt.scatter(y_pred, residuals)\n",
    "plt.xlabel(\"Predicted values\")\n",
    "plt.ylabel(\"Residuals\")\n",
    "plt.title(\"Residuals vs Fitted\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variance Inflation Factor\n",
    "\n",
    "# Calculate the VIF for each estimated coefficient using statsmodels package\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "\n",
    "vif = pd.DataFrame()\n",
    "vif[\"VIF Factor\"] = [variance_inflation_factor(X.values, i) for i in range(X.shape[1])]\n",
    "vif"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frames = {\n",
    "    \"gdp\": gdp,\n",
    "    # \"lit\": lit,\n",
    "    # \"lif\": lif,\n",
    "    # \"urb\": urb, \n",
    "    # \"pop\": pop\n",
    "}\n",
    "X, y = clean_up(incomet, frames)\n",
    "print(X.shape, y.shape)\n",
    "\n",
    "est2 = sm.add_constant(X)\n",
    "est = sm.OLS(y, est2).fit()\n",
    "print(est.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Income bottom 10%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frames = {\n",
    "    \"gdp\": gdp,\n",
    "    # \"lit\": lit,\n",
    "    \"lif\": lif,\n",
    "    \"urb\": urb,\n",
    "    \"pop\": pop\n",
    "}\n",
    "X, y = clean_up(incomeb, frames)\n",
    "print(X.shape, y.shape)\n",
    "\n",
    "est2 = sm.add_constant(X)\n",
    "est = sm.OLS(y, est2).fit()\n",
    "print(est.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform gdp to log gdp\n",
    "# X[\"gdp\"] = np.log(X[\"gdp\"]) \n",
    "\n",
    "X[\"log_gdp\"] = np.log(X[\"gdp\"])\n",
    "X[\"gdp_2\"] = X[\"gdp\"] ** 2\n",
    "# X[\"gdp_3\"] = X[\"gdp\"] ** 3\n",
    "\n",
    "# gdp = 0.137\n",
    "# gdp + log gdp = 0.139\n",
    "# gdp + gdp_2 = 0.147\n",
    "# gdp + log gdp + gdp_2 = 0.160\n",
    "# gdp + gdp_3 = 0.037\n",
    "\n",
    "\n",
    "print(X.columns)\n",
    "est2 = sm.add_constant(X)\n",
    "est = sm.OLS(y, est2).fit()\n",
    "print(est.summary())\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Heteroscedasticity Test\n",
    "\n",
    "# Plot the residual error terms against the y_pred\n",
    "y_pred = est.predict(est2)\n",
    "\n",
    "residuals = y - y_pred\n",
    "plt.scatter(y_pred, residuals)\n",
    "plt.xlabel(\"Predicted values\")\n",
    "plt.ylabel(\"Residuals\")\n",
    "plt.title(\"Residuals vs Fitted\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variance Inflation Factor\n",
    "\n",
    "# Calculate the VIF for each estimated coefficient using statsmodels package\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "\n",
    "vif = pd.DataFrame()\n",
    "vif[\"VIF Factor\"] = [variance_inflation_factor(X.values, i) for i in range(X.shape[1])]\n",
    "vif"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frames = {\n",
    "    \"gdp\": gdp,\n",
    "    # \"lit\": lit,\n",
    "    # \"lif\": lif,\n",
    "    # \"urb\": urb,\n",
    "    \"pop\": pop\n",
    "}\n",
    "X, y = clean_up(incomeb, frames)\n",
    "print(X.shape, y.shape)\n",
    "\n",
    "est2 = sm.add_constant(X)\n",
    "est = sm.OLS(y, est2).fit()\n",
    "print(est.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Drastic decrease in explanation if urb is removed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Discussion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
